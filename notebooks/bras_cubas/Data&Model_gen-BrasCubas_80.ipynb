{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "Cb3ztjI91g4g",
    "outputId": "8105d586-494e-47c8-d2ed-85efac26273a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "import heapq\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0u8O2sg1x9D"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.models import Sequential, Input\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "# SEQUENCE SIZE PARAMETERS\n",
    "CHARACTER_NUMBER_PREDICTION = 80\n",
    "DATA_SET_COLLECTION_ITERATIONS = 50_000\n",
    "SET_VARIABILITY = 3\n",
    "\n",
    "# RNN PARAMETERS\n",
    "EMB_DIM = 256\n",
    "SEQ_UNITS = 256\n",
    "DROP = .1\n",
    "\n",
    "# TRAINING PARAMETERS\n",
    "TEST_SIZE = 0.2\n",
    "EPOCHS = 400\n",
    "BATCH_SIZE = 256\n",
    "VALIDATION_SPLIT = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ht9k06l411rL"
   },
   "outputs": [],
   "source": [
    "contentDf = pd.read_csv('bras_cubas_paragraphs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7bzrODFBKsA"
   },
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(text):\n",
    "\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError: # unicode is a default on python 3 \n",
    "        pass\n",
    "\n",
    "    text = unicodedata.normalize('NFD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode(\"utf-8\")\n",
    "\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKBLSpHGBWIO"
   },
   "outputs": [],
   "source": [
    "# Arrays we'll use to store our dataset\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "# Looping through our corpus...\n",
    "for i in range(DATA_SET_COLLECTION_ITERATIONS):\n",
    "    # ... selecting a random paragraph from our book...\n",
    "    paragraphIndex = np.random.randint(0, len(contentDf.paragraphs))\n",
    "    currentParagraph = contentDf.paragraphs[paragraphIndex]\n",
    "  \n",
    "    # ... sampling a slice of the selected paragraph...\n",
    "    #   aux = 1\n",
    "    #   dontAddThisSample = False\n",
    "    #   while(len(currentParagraph) - CHARACTER_NUMBER_PREDICTION + 1 < CHARACTER_NUMBER_PREDICTION + 1):\n",
    "    #     # currentParagraph += contentDf.paragraphs[np.random.randint(0, len(contentDf.paragraphs))]\n",
    "    #     if (paragraphIndex + aux < len(contentDf.paragraphs)):\n",
    "    #         currentParagraph += contentDf.paragraphs[paragraphIndex + aux]\n",
    "    #         aux += 1\n",
    "    #     else:\n",
    "    #         dontAddThisSample = True\n",
    "    #         break;\n",
    "        \n",
    "    #   if (dontAddThisSample):\n",
    "    #     continue\n",
    "\n",
    "    if (len(currentParagraph) < CHARACTER_NUMBER_PREDICTION + 1):\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    \n",
    "    paragraphRegion = np.random.randint(0, len(currentParagraph) - CHARACTER_NUMBER_PREDICTION)\n",
    "    \n",
    "    # Checking how many different chars are in the selected paragraph region\n",
    "    nChars = len(set(currentParagraph[paragraphRegion : paragraphRegion + CHARACTER_NUMBER_PREDICTION]))\n",
    "    \n",
    "    if (nChars < SET_VARIABILITY):\n",
    "        continue\n",
    "  \n",
    "    \n",
    "    # Adding an excerpt of the paragraph to our X and y data.\n",
    "    X_data.append(currentParagraph[paragraphRegion : paragraphRegion + CHARACTER_NUMBER_PREDICTION].casefold())\n",
    "    y_data.append(currentParagraph[paragraphRegion + CHARACTER_NUMBER_PREDICTION].casefold())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31758, 31758)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_data), len(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFbfudiPN5MP"
   },
   "source": [
    "In the cells below, we'll instantiate and fit a tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xVFYTOMkHjGJ"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(\n",
    "    num_words=500,\n",
    "    char_level=True,\n",
    "    filters=None,\n",
    "    lower=False,\n",
    "    oov_token=chr(1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "h1ml7sn-LmvV",
    "outputId": "846ab1e4-0915-4bbf-ade7-e530ccffd60b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 397 ms, sys: 8 Âµs, total: 397 ms\n",
      "Wall time: 397 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer.fit_on_texts(X_data)\n",
    "tokenizer.fit_on_texts(y_data)\n",
    "word_index = tokenizer.word_index\n",
    "index_word = tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hs3LJUSBL8i0"
   },
   "outputs": [],
   "source": [
    "X = np.array(tokenizer.texts_to_sequences(X_data), dtype=np.int32)\n",
    "y = np.array(list(map(word_index.get, y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "737CDqaGMkjf",
    "outputId": "a2fcdcf8-a09e-4a13-eb75-f18584ae39a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  7  3 ...  5  2 23]\n",
      " [22 10  9 ...  2 19  4]\n",
      " [13  8  5 ...  2 12  7]\n",
      " ...\n",
      " [ 2 18  4 ... 15  4 22]\n",
      " [13  4  2 ...  6  4  2]\n",
      " [10  4  2 ...  9  3  7]]\n",
      "[4 7 6 ... 8 3 6]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eeTG9ePCOuPA",
    "outputId": "419dcf5e-c5e4-41de-a313-593c8f3bfded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (25406, 80), Y train shape : (25406,), X test shape: (6352, 80), Y test shape: (6352,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE)\n",
    "print(f\"X train shape: {X_train.shape}, Y train shape : {y_train.shape}, X test shape: {X_test.shape}, Y test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X_VM3plzRsoQ",
    "outputId": "73a32fbe-5fd2-4e74-bfd3-4fe2256eaded"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PmeWLbt-OMnZ"
   },
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJZVax2mOO0T"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index) + 1, EMB_DIM, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(DROP))\n",
    "model.add(Bidirectional(GRU(SEQ_UNITS, return_sequences=True, dropout=DROP,recurrent_dropout=DROP)))\n",
    "model.add(SpatialDropout1D(DROP))\n",
    "model.add(Bidirectional(GRU(SEQ_UNITS, return_sequences=True, dropout=DROP,recurrent_dropout=DROP)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(len(tokenizer.word_index), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "PPwvhgBOP9LX",
    "outputId": "41b66a9e-0aa6-48af-fde5-a9ca5d7b258a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 80, 256)           17152     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 80, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 80, 512)           787968    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 80, 512)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 80, 512)           1181184   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 66)                33858     \n",
      "=================================================================\n",
      "Total params: 2,020,162\n",
      "Trainable params: 2,020,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=RMSprop(lr=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "id": "M7TKfzAYQOxj",
    "outputId": "6627de62-d5f4-4dc7-d664-9d5eb2473bbf",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20324 samples, validate on 5082 samples\n",
      "Epoch 1/400\n",
      "20324/20324 [==============================] - 19s 916us/step - loss: 2.9607 - sparse_categorical_accuracy: 0.1955 - val_loss: 2.6185 - val_sparse_categorical_accuracy: 0.2497\n",
      "Epoch 2/400\n",
      "20324/20324 [==============================] - 16s 807us/step - loss: 2.4487 - sparse_categorical_accuracy: 0.2866 - val_loss: 2.4132 - val_sparse_categorical_accuracy: 0.2712\n",
      "Epoch 3/400\n",
      "20324/20324 [==============================] - 16s 805us/step - loss: 2.2744 - sparse_categorical_accuracy: 0.3206 - val_loss: 2.3306 - val_sparse_categorical_accuracy: 0.2684\n",
      "Epoch 4/400\n",
      "20324/20324 [==============================] - 16s 805us/step - loss: 2.1879 - sparse_categorical_accuracy: 0.3372 - val_loss: 2.2525 - val_sparse_categorical_accuracy: 0.3074\n",
      "Epoch 5/400\n",
      "20324/20324 [==============================] - 16s 807us/step - loss: 2.1215 - sparse_categorical_accuracy: 0.3523 - val_loss: 2.1739 - val_sparse_categorical_accuracy: 0.3306\n",
      "Epoch 6/400\n",
      "20324/20324 [==============================] - 16s 807us/step - loss: 2.0596 - sparse_categorical_accuracy: 0.3702 - val_loss: 2.1120 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 7/400\n",
      "20324/20324 [==============================] - 16s 808us/step - loss: 1.9916 - sparse_categorical_accuracy: 0.3871 - val_loss: 2.0935 - val_sparse_categorical_accuracy: 0.3613\n",
      "Epoch 8/400\n",
      "20324/20324 [==============================] - 16s 806us/step - loss: 1.9243 - sparse_categorical_accuracy: 0.4043 - val_loss: 2.0484 - val_sparse_categorical_accuracy: 0.3739\n",
      "Epoch 9/400\n",
      "20324/20324 [==============================] - 16s 808us/step - loss: 1.8598 - sparse_categorical_accuracy: 0.4217 - val_loss: 2.0398 - val_sparse_categorical_accuracy: 0.3835\n",
      "Epoch 10/400\n",
      "20324/20324 [==============================] - 16s 808us/step - loss: 1.7871 - sparse_categorical_accuracy: 0.4483 - val_loss: 1.9889 - val_sparse_categorical_accuracy: 0.3975\n",
      "Epoch 11/400\n",
      "20324/20324 [==============================] - 16s 807us/step - loss: 1.7105 - sparse_categorical_accuracy: 0.4680 - val_loss: 2.0085 - val_sparse_categorical_accuracy: 0.3987\n",
      "CPU times: user 7min 3s, sys: 36.1 s, total: 7min 39s\n",
      "Wall time: 3min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_split=VALIDATION_SPLIT,\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss',patience=1,\n",
    "                                            min_delta=1e-7)]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = X_test[0].copy().reshape((1, -1))\n",
    "original = ''.join(map(tokenizer.index_word.get, curr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_seq = []\n",
    "while True:\n",
    "    _next = model.predict_classes(curr)[0]\n",
    "    next_char = tokenizer.index_word[_next]\n",
    "    if next_char == ' ':\n",
    "        break\n",
    "    next_seq.append(next_char)\n",
    "    curr[0, 0 : -1] = curr[0, 1 :]\n",
    "    curr[0, -1] = _next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " seriam tenues, e compradas a troco da solidÃ£o. sem filhos! nÃ£o; impossivel. dis se\n"
     ]
    }
   ],
   "source": [
    "print(original, ''.join(next_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  6,  4,  8,  7,  3,  9,  2, 13,  4, 11, 10,  4,  6, 16,  2,  4,\n",
       "        2, 14,  5,  9, 17,  8,  3, 12,  3,  6,  2,  3,  2, 13,  8,  5, 14,\n",
       "        5,  2, 12,  3,  2,  6,  5, 15,  7, 12, 25,  5, 20,  2,  6,  4,  9,\n",
       "        2, 24,  7, 15, 19,  5,  6, 35,  2, 11, 25,  5, 27,  2,  7,  9, 17,\n",
       "        5,  6,  6,  7, 18,  4, 15, 20,  2, 12,  7,  6], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " seriam tenues, e compradas a troco da solidÃ£o. sem filhos! nÃ£o; impossivel. dis -- se e pera verte e pera\n",
      "deiramente christÃ£o. todavia, nÃ£o neguei aos amigos as vantagens pecuniarias que --  fante a menha vertigo e\n",
      "stume jantava ahi; mas, nÃ£o tendo deliberadamente andado, nenhum merecimento da  -- meneito de meite de memente com\n",
      "obrigado a aceitar as duas; creio que posso ser separadamente homem casado ou ho -- mente de meito de conteiro, e\n",
      "os famulos, que naturalmente se desforravam assim da condiÃ§Ã£o servil, e tudo iss -- e e a menos de por\n",
      "sentar ao pÃ© da filha do damasceno, uma d. eulalia, ou mais familiarmente nhÃ£-lÃ³ --  e eu conteito de perteiro\n",
      "te, ao menos, uma parte cheia de prazeres, de agitaÃ§Ãµes, de sustos,â capeada de  -- porte em porte de memos e\n",
      " eu nasci, estava jÃ¡ em todo o explendor da gloria e do poder; era imperador e g -- ranha para de canteira cama cantava\n",
      " o humanitismo; elle Ã© o grande regaÃ§o dos espiritos, o mar eterno em que mergul -- a e eu pera e eu\n",
      " indifferenÃ§a. eu mesmo, atÃ© entÃ£o, tinha-vos em mÃ¡ conta, zangava-me quando vos -- te e pereceiro. e menei e\n",
      ". nÃ£o importa a edade do adulado; a mulher ha de ter sempre para elle uns ares d -- e porteito de conteiro de paraÃ§ava\n",
      "incas borba fez-me parar e observar os cÃ£es. eram dous. notou que ao pÃ© delles e --  porte de consisse para com\n",
      "o, ponderou elle, no fim de um instante, mas ninguem me negarÃ¡ sentimento, se nÃ£ -- o canha para per para de\n",
      "u-me afflicta. que idÃ©a Ã© essa de provocar o governo, sem necessidade, quando po -- r e veria per pera de\n",
      "de de amor era a mesma; a differenÃ§a Ã© que a chamma perdera o tresloucado dos pr -- eceteiro de porte de perta de\n",
      "o, disse eu, arranjei recursos...temos muito dinheiro, terÃ¡s tudo o que quizeres -- .... nÃ£o e temporia e por\n",
      "beira das calÃ§as,â umas largas calÃ§as de enfiarâ , ou na gaveta da mesa, ou ao p -- ades a conteiro de menho de\n",
      ". nÃ£o receies perder esse andrajo que Ã© teu orgulho; provarÃ¡s ainda, por algumas --  com o perdida de menos\n",
      "temos a este proposito uma anecdota. foi no tempo da minha vida parlamentar; era --  menei a menos para a\n",
      "adia! murmurou elle sem responder ao pedido. um cadaver... o mar... o ceu... o n -- o peria... me verte de mente\n",
      "ebi-o sem alvoroÃ§o. elle esteve alguns instantes de pÃ©, a olhar para mim; depois --  de podia de para de\n",
      "o grave, e aliÃ¡s infimo, porque o maior defeito deste livro Ã©s tu, leitor. tu te -- mporia o porte de perte a\n",
      "illaÃ§a, glosador insigne, que accrescentou aos pratos de casa o acepipe das musa --  de porte de menos e\n",
      ", porque a candidatura de lobo neves era apoiada por grandes influencias. cedi;  -- e parecia de cousa de paraÃ§a\n",
      "sta de primavera, um amanhecer da alma publica. eramos dous rapazes, o povo e eu --  conteito de menos e meu\n",
      "o nas mÃ£os, e o espirito ainda mais cabisbaixo do que a figura,â ou jururÃº, como --  este e menos e menos\n",
      "as cousas externas, embelleza-se no invisivel, apprehende o impalpavel, desvincu -- ei a porteiro de meito de\n",
      "steza tornou logo, a tristeza de morrer sem me ver posto em algum logar alto, co -- m o conteiro. nÃ£o e e\n",
      " nÃ£o sei... sÃ£o bem frouxos versos. jurei-lhe que nÃ£o; pedi que os reunisse e me -- nei e conteiro e menei e\n",
      " ponto, que foi preciso deital-o Ã¡ margem, onde o realismo o veiu achar, comido  -- a menos... nÃ£o e menos.. ponte\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    curr = X_test[i].copy().reshape((1, -1))\n",
    "    original = ''.join(map(tokenizer.index_word.get, curr[0]))\n",
    "    blank_count = 0\n",
    "    next_seq = []\n",
    "    while True:\n",
    "        _next = model.predict_classes(curr)[0]\n",
    "        next_char = tokenizer.index_word[_next]\n",
    "        if next_char == ' ':\n",
    "            blank_count += 1\n",
    "        if blank_count == 6:\n",
    "            break\n",
    "        next_seq.append(next_char)\n",
    "        curr[0, 0 : -1] = curr[0, 1 :]\n",
    "        curr[0, -1] = _next\n",
    "        \n",
    "    print(original, '--', ''.join(next_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('bras_cubas_80-keras_model.h5')\n",
    "with open('bras_cubas_80-index_word.json', 'w') as f:\n",
    "    json.dump(tokenizer.index_word, f, ensure_ascii=False)\n",
    "with open('bras_cubas_80-word_index.json', 'w') as f:\n",
    "    json.dump(tokenizer.word_index, f, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bras-cubas-model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
