{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "Cb3ztjI91g4g",
    "outputId": "8105d586-494e-47c8-d2ed-85efac26273a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "import heapq\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0u8O2sg1x9D"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.models import Sequential, Input\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "# SEQUENCE SIZE PARAMETERS\n",
    "CHARACTER_NUMBER_PREDICTION = 40\n",
    "DATA_SET_COLLECTION_ITERATIONS = 50_000\n",
    "SET_VARIABILITY = 3\n",
    "\n",
    "# RNN PARAMETERS\n",
    "EMB_DIM = 256\n",
    "SEQ_UNITS = 128\n",
    "DROP = .1\n",
    "\n",
    "# TRAINING PARAMETERS\n",
    "TEST_SIZE = 0.2\n",
    "EPOCHS = 400\n",
    "BATCH_SIZE = 256\n",
    "VALIDATION_SPLIT = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ht9k06l411rL"
   },
   "outputs": [],
   "source": [
    "contentDf = pd.read_csv('bras_cubas_paragraphs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7bzrODFBKsA"
   },
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(text):\n",
    "\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError: # unicode is a default on python 3 \n",
    "        pass\n",
    "\n",
    "    text = unicodedata.normalize('NFD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode(\"utf-8\")\n",
    "\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKBLSpHGBWIO"
   },
   "outputs": [],
   "source": [
    "# Arrays we'll use to store our dataset\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "# Looping through our corpus...\n",
    "for i in range(DATA_SET_COLLECTION_ITERATIONS):\n",
    "    # ... selecting a random paragraph from our book...\n",
    "    paragraphIndex = np.random.randint(0, len(contentDf.paragraphs))\n",
    "    currentParagraph = contentDf.paragraphs[paragraphIndex]\n",
    "  \n",
    "    # ... sampling a slice of the selected paragraph...\n",
    "    #   aux = 1\n",
    "    #   dontAddThisSample = False\n",
    "    #   while(len(currentParagraph) - CHARACTER_NUMBER_PREDICTION + 1 < CHARACTER_NUMBER_PREDICTION + 1):\n",
    "    #     # currentParagraph += contentDf.paragraphs[np.random.randint(0, len(contentDf.paragraphs))]\n",
    "    #     if (paragraphIndex + aux < len(contentDf.paragraphs)):\n",
    "    #         currentParagraph += contentDf.paragraphs[paragraphIndex + aux]\n",
    "    #         aux += 1\n",
    "    #     else:\n",
    "    #         dontAddThisSample = True\n",
    "    #         break;\n",
    "        \n",
    "    #   if (dontAddThisSample):\n",
    "    #     continue\n",
    "\n",
    "    if (len(currentParagraph) < CHARACTER_NUMBER_PREDICTION + 1):\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    \n",
    "    paragraphRegion = np.random.randint(0, len(currentParagraph) - CHARACTER_NUMBER_PREDICTION)\n",
    "    \n",
    "    # Checking how many different chars are in the selected paragraph region\n",
    "    nChars = len(set(currentParagraph[paragraphRegion : paragraphRegion + CHARACTER_NUMBER_PREDICTION]))\n",
    "    \n",
    "    if (nChars < SET_VARIABILITY):\n",
    "        continue\n",
    "  \n",
    "    \n",
    "    # Adding an excerpt of the paragraph to our X and y data.\n",
    "    X_data.append(currentParagraph[paragraphRegion : paragraphRegion + CHARACTER_NUMBER_PREDICTION].casefold())\n",
    "    y_data.append(currentParagraph[paragraphRegion + CHARACTER_NUMBER_PREDICTION].casefold())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37923, 37923)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_data), len(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFbfudiPN5MP"
   },
   "source": [
    "In the cells below, we'll instantiate and fit a tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xVFYTOMkHjGJ"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(\n",
    "    num_words=500,\n",
    "    char_level=True,\n",
    "    filters=None,\n",
    "    lower=False,\n",
    "    oov_token=chr(1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "h1ml7sn-LmvV",
    "outputId": "846ab1e4-0915-4bbf-ade7-e530ccffd60b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 262 ms, sys: 0 ns, total: 262 ms\n",
      "Wall time: 261 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer.fit_on_texts(X_data)\n",
    "tokenizer.fit_on_texts(y_data)\n",
    "word_index = tokenizer.word_index\n",
    "index_word = tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hs3LJUSBL8i0"
   },
   "outputs": [],
   "source": [
    "X = np.array(tokenizer.texts_to_sequences(X_data), dtype=np.int32)\n",
    "y = np.array(list(map(word_index.get, y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "737CDqaGMkjf",
    "outputId": "a2fcdcf8-a09e-4a13-eb75-f18584ae39a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2 12  4 ... 12  4  2]\n",
      " [ 5  2  4 ...  4  2 16]\n",
      " [ 2 14  3 ... 22 10  4]\n",
      " ...\n",
      " [ 2  4 15 ... 25  7 15]\n",
      " [ 2  3  2 ...  2  5  7]\n",
      " [12  7  3 ...  3  2  8]]\n",
      "[ 9  5 20 ... 19 13  4]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eeTG9ePCOuPA",
    "outputId": "419dcf5e-c5e4-41de-a313-593c8f3bfded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (30338, 40), Y train shape : (30338,), X test shape: (7585, 40), Y test shape: (7585,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE)\n",
    "print(f\"X train shape: {X_train.shape}, Y train shape : {y_train.shape}, X test shape: {X_test.shape}, Y test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X_VM3plzRsoQ",
    "outputId": "73a32fbe-5fd2-4e74-bfd3-4fe2256eaded"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PmeWLbt-OMnZ"
   },
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJZVax2mOO0T"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index) + 1, EMB_DIM, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(DROP))\n",
    "model.add(Bidirectional(GRU(SEQ_UNITS, return_sequences=True, dropout=DROP,recurrent_dropout=DROP)))\n",
    "model.add(SpatialDropout1D(DROP))\n",
    "model.add(Bidirectional(GRU(SEQ_UNITS, return_sequences=True, dropout=DROP,recurrent_dropout=DROP)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(len(tokenizer.word_index), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "PPwvhgBOP9LX",
    "outputId": "41b66a9e-0aa6-48af-fde5-a9ca5d7b258a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 40, 256)           17152     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 40, 256)           295680    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 40, 256)           295680    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 66)                16962     \n",
      "=================================================================\n",
      "Total params: 625,474\n",
      "Trainable params: 625,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=RMSprop(lr=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "id": "M7TKfzAYQOxj",
    "outputId": "6627de62-d5f4-4dc7-d664-9d5eb2473bbf",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24270 samples, validate on 6068 samples\n",
      "Epoch 1/400\n",
      "24270/24270 [==============================] - 12s 487us/step - loss: 2.9164 - sparse_categorical_accuracy: 0.2014 - val_loss: 2.6376 - val_sparse_categorical_accuracy: 0.2347\n",
      "Epoch 2/400\n",
      "24270/24270 [==============================] - 10s 397us/step - loss: 2.4977 - sparse_categorical_accuracy: 0.2783 - val_loss: 2.3889 - val_sparse_categorical_accuracy: 0.2874\n",
      "Epoch 3/400\n",
      "24270/24270 [==============================] - 10s 397us/step - loss: 2.3253 - sparse_categorical_accuracy: 0.3093 - val_loss: 2.2740 - val_sparse_categorical_accuracy: 0.3159\n",
      "Epoch 4/400\n",
      "24270/24270 [==============================] - 10s 396us/step - loss: 2.2334 - sparse_categorical_accuracy: 0.3302 - val_loss: 2.1924 - val_sparse_categorical_accuracy: 0.3309\n",
      "Epoch 5/400\n",
      "24270/24270 [==============================] - 10s 396us/step - loss: 2.1605 - sparse_categorical_accuracy: 0.3476 - val_loss: 2.1472 - val_sparse_categorical_accuracy: 0.3476\n",
      "Epoch 6/400\n",
      "24270/24270 [==============================] - 10s 398us/step - loss: 2.1054 - sparse_categorical_accuracy: 0.3614 - val_loss: 2.0991 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 7/400\n",
      "24270/24270 [==============================] - 10s 399us/step - loss: 2.0591 - sparse_categorical_accuracy: 0.3730 - val_loss: 2.0407 - val_sparse_categorical_accuracy: 0.3741\n",
      "Epoch 8/400\n",
      "24270/24270 [==============================] - 10s 400us/step - loss: 2.0095 - sparse_categorical_accuracy: 0.3897 - val_loss: 2.0139 - val_sparse_categorical_accuracy: 0.3869\n",
      "Epoch 9/400\n",
      "24270/24270 [==============================] - 10s 400us/step - loss: 1.9660 - sparse_categorical_accuracy: 0.4015 - val_loss: 1.9768 - val_sparse_categorical_accuracy: 0.3983\n",
      "Epoch 10/400\n",
      "24270/24270 [==============================] - 10s 400us/step - loss: 1.9246 - sparse_categorical_accuracy: 0.4130 - val_loss: 1.9580 - val_sparse_categorical_accuracy: 0.3985\n",
      "Epoch 11/400\n",
      "24270/24270 [==============================] - 10s 399us/step - loss: 1.8854 - sparse_categorical_accuracy: 0.4254 - val_loss: 1.9278 - val_sparse_categorical_accuracy: 0.4128\n",
      "Epoch 12/400\n",
      "24270/24270 [==============================] - 10s 400us/step - loss: 1.8403 - sparse_categorical_accuracy: 0.4372 - val_loss: 1.9107 - val_sparse_categorical_accuracy: 0.4192\n",
      "Epoch 13/400\n",
      "24270/24270 [==============================] - 10s 401us/step - loss: 1.8063 - sparse_categorical_accuracy: 0.4466 - val_loss: 1.8801 - val_sparse_categorical_accuracy: 0.4311\n",
      "Epoch 14/400\n",
      "24270/24270 [==============================] - 10s 399us/step - loss: 1.7709 - sparse_categorical_accuracy: 0.4609 - val_loss: 1.8575 - val_sparse_categorical_accuracy: 0.4354\n",
      "Epoch 15/400\n",
      "24270/24270 [==============================] - 10s 399us/step - loss: 1.7287 - sparse_categorical_accuracy: 0.4713 - val_loss: 1.8390 - val_sparse_categorical_accuracy: 0.4489\n",
      "Epoch 16/400\n",
      "24270/24270 [==============================] - 10s 401us/step - loss: 1.6972 - sparse_categorical_accuracy: 0.4803 - val_loss: 1.8243 - val_sparse_categorical_accuracy: 0.4476\n",
      "Epoch 17/400\n",
      "24270/24270 [==============================] - 10s 401us/step - loss: 1.6619 - sparse_categorical_accuracy: 0.4958 - val_loss: 1.7969 - val_sparse_categorical_accuracy: 0.4596\n",
      "Epoch 18/400\n",
      "24270/24270 [==============================] - 10s 400us/step - loss: 1.6314 - sparse_categorical_accuracy: 0.5025 - val_loss: 1.7991 - val_sparse_categorical_accuracy: 0.4626\n",
      "CPU times: user 6min 46s, sys: 31.5 s, total: 7min 18s\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_split=VALIDATION_SPLIT,\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss',patience=1,\n",
    "                                            min_delta=1e-7)]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = X_test[0].copy().reshape((1, -1))\n",
    "original = ''.join(map(tokenizer.index_word.get, curr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_seq = []\n",
    "while True:\n",
    "    _next = model.predict_classes(curr)[0]\n",
    "    next_char = tokenizer.index_word[_next]\n",
    "    if next_char == ' ':\n",
    "        break\n",
    "    next_seq.append(next_char)\n",
    "    curr[0, 0 : -1] = curr[0, 1 :]\n",
    "    curr[0, -1] = _next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i-ni-ti-va! repetiu, batendo as syllabas \n"
     ]
    }
   ],
   "source": [
    "print(original, ''.join(next_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 26, 11,  7, 26, 13,  7, 26, 18,  3, 34,  2,  8,  4, 16,  4, 13,\n",
       "        7, 10, 17,  2, 23,  3, 13,  4, 11, 12,  5,  2,  3,  6,  2,  6, 40,\n",
       "       15, 15,  3, 23,  3,  6], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i-ni-ti-va! repetiu, batendo as syllabas --  de corraço. e despor a\n",
      "ual! passei mal a noite; o diabo da asth -- amor. de corricar a corrica. de\n",
      "já em opposição, entrando nesse numero o --  perdo do corrica. de corricar\n",
      " tempo de levantar e espairecer, como um --  corrica. a maria de um\n",
      " vê. morrer, meu anjo? que idéas são ess -- e a mão de cara a\n",
      "fica o espirito humano,     supprime a d -- espor a morte. e de corricar\n",
      "já lhe fui agradecer este signal de cons -- entente. não sei a maria de\n",
      "sacudir dos olhos a ceremonia do enterro -- . não sei a maria de\n",
      "goista! prefere ver-me padecer todos os  -- outros. e de cara a marida\n",
      " a fizeram. abençoadas pernas! e ha quem --  de cara a marida de\n",
      "mais a negar que era noiva excellente; m -- as outra de casa. a maria\n",
      "murei eu olhando para o tecto do corredo -- ..... e disse eu.... não sei\n",
      "o politica eram bens dignos de apreço; o --  menhora de cara a menhora\n",
      "a velha prataria do tempo de d. josé i,  -- despor a marido. e disse elle.\n",
      "morta!\" esta ultima palavra foi para mim -- .... a maria de um minha!\n",
      "'o; ella sorriu, e foi guardar a joia, e --  a marida de cara a\n",
      "stavam tambem, não menos tristes e não m -- eiro. a maria a maria a\n",
      "ão tem que adivinhar: não veiu por outra --  de cara a marida de\n",
      "ue fazer, e até chegou a me dar casa. es -- tava com a mais de cantar......\n",
      "xaminar as duas cousas, a candidatura e  -- de cara a manho. não sei\n",
      "le a que você deseja para si, a do campo -- ria de um cara a mão.\n",
      "emorada que fosse a operação do toucado, --  e destres de corricar a\n",
      " e apezar disso deixei-me ficar, não men -- to de cara a maria..... a\n",
      "ima palavra, recuei um pouco, tomado de  -- corrica. a corrica. de casação de\n",
      "de machiavelli; circumstancia que levou  -- a maria de um delhora de\n",
      " camarote, que uma só italiana vale por  -- a cara de cara a marida\n",
      "dos desceram a passear. vi-o conversar c -- om o corrico. a marido de\n",
      "radecimento.— agora é devéras? disse ell -- e. não sei a mão de\n",
      "ou; mas, amanhã ou depois, hão de vir ja -- ntaria....... a maria a maria a\n",
      "— que foi o que? creio que não houve nad -- a. de cara a cara de\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    curr = X_test[i].copy().reshape((1, -1))\n",
    "    original = ''.join(map(tokenizer.index_word.get, curr[0]))\n",
    "    blank_count = 0\n",
    "    next_seq = []\n",
    "    while True:\n",
    "        _next = model.predict_classes(curr)[0]\n",
    "        next_char = tokenizer.index_word[_next]\n",
    "        if next_char == ' ':\n",
    "            blank_count += 1\n",
    "        if blank_count == 6:\n",
    "            break\n",
    "        next_seq.append(next_char)\n",
    "        curr[0, 0 : -1] = curr[0, 1 :]\n",
    "        curr[0, -1] = _next\n",
    "        \n",
    "    print(original, '--', ''.join(next_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('bras_cubas_40-keras_model.h5')\n",
    "with open('bras_cubas_40-index_word.json', 'w') as f:\n",
    "    json.dump(tokenizer.index_word, f, ensure_ascii=False)\n",
    "with open('bras_cubas_40-word_index.json', 'w') as f:\n",
    "    json.dump(tokenizer.word_index, f, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bras-cubas-model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
